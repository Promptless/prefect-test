---
title: Quickstart
description: Get started with Prefect, the easiest way to orchestrate and observe your data pipelines
---

import Installation from '/snippets/installation.mdx'

Prefect is an orchestration and observability platform that empowers developers to build and scale workflows quickly.
In this quickstart, you will use Prefect to convert the following Python script to a schedulable, observable, resilient, and deployable workflow in minutes:

```python
import httpx

def get_repo_info():
    """Fetch statistics about the Prefect repository"""
    url = "https://api.github.com/repos/PrefectHQ/prefect"
    response = httpx.get(url)
    repo = response.json()
    print("PrefectHQ/prefect repository statistics ü§ì:")
    print(f"Stars üå† : {repo['stargazers_count']}")

if __name__ == "__main__":
    get_repo_info()
```

## Install Prefect

<Installation />

<Tip>
See [Install Prefect](/3.0/get-started/install/) for more details on installation.
</Tip>

## Connect to a Prefect API

Connect to a Prefect API:

<Tabs>
  <Tab title="Self-hosted">
1. Start a local API server:

   ```bash
   prefect server start
   ```

1. Open the Prefect dashboard in your browser at [http://localhost:4200](http://localhost:4200).
  </Tab>
  <Tab title="Prefect Cloud">
1. Head to [https://app.prefect.cloud/](https://app.prefect.cloud/) and sign in or create a forever-free Prefect Cloud account.
1. Log in to Prefect Cloud from your development environment:

   ```bash
   prefect cloud login
   ```

1. Choose **Log in with a web browser** and click the **Authorize** button in the browser window that opens.

Your CLI is now authenticated with your Prefect Cloud account through a locally stored API key that expires in 30 days.

If you have any issues with browser-based authentication, you can [authenticate with a manually created API key](/3.0/manage/cloud/manage-users/api-keys/) instead.
  </Tab>
</Tabs>

## Convert your script to a Prefect workflow

The easiest way to convert a Python script into a workflow is to add a `@flow` decorator to the script's entrypoint.
This will create a corresponding [flow](/3.0/develop/write-flows/). 

Adding `@task` decorators to any functions called by the flow converts them to [tasks](/3.0/develop/write-tasks/). 
Tasks receive metadata about upstream dependencies and the state of those dependencies before they run.
Prefect will then record these dependencies and states as it orchestrates these tasks.

```python my_gh_workflow.py
import httpx   # an HTTP client library and dependency of Prefect
from prefect import flow, task

@task(retries=2)
def get_repo_info(repo_owner: str, repo_name: str):
    """Get info about a repo - will retry twice after failing"""
    url = f"https://api.github.com/repos/{repo_owner}/{repo_name}"
    api_response = httpx.get(url)
    api_response.raise_for_status()
    repo_info = api_response.json()
    return repo_info

@task
def get_contributors(repo_info: dict):
    """Get contributors for a repo"""
    contributors_url = repo_info["contributors_url"]
    response = httpx.get(contributors_url)
    response.raise_for_status()
    contributors = response.json()
    return contributors

@flow(log_prints=True)
def log_repo_info(repo_owner: str = "PrefectHQ", repo_name: str = "prefect"):
    """
    Given a GitHub repository, logs the number of stargazers
    and contributors for that repo.
    """
    repo_info = get_repo_info(repo_owner, repo_name)
    print(f"Stars üå† : {repo_info['stargazers_count']}")

    contributors = get_contributors(repo_info)
    print(f"Number of contributors üë∑: {len(contributors)}")

if __name__ == "__main__":
    log_repo_info()
```

<Note>
The `log_prints=True` argument provided to the `@flow` decorator automatically converts any `print` statements within the function to `INFO` level logs.
</Note>

## Run your flow

You can run your Prefect flow just as you would a Python script:

```bash
python my_gh_workflow.py
```

Prefect automatically tracks the state of the flow run and logs the output, which can be viewed directly in the terminal or in the UI.

```
    _____________________________________________________________________________________________
    | Provisioning infrastructure for your work pool my-aci-work-pool will require:             |
    |                                                                                           |
    |     Updates in subscription Azure subscription 1                                          |
    |                                                                                           |
    |         - Create a resource group in location eastus                                      |
    |         - Create an app registration in Azure AD prefect-aci-push-pool-app                |
    |         - Create/use a service principal for app registration                             |
    |         - Generate a secret for app registration                                          |
    |         - Create an Azure Container Registry with prefix prefect                           |
    |         - Create an identity prefect-acr-identity to allow access to the created registry |
    |         - Assign Contributor role to service account                                      |
    |         - Create an ACR registry for image hosting                                        |
    |         - Create an identity for Azure Container Instance to allow access to the registry |
    |                                                                                           |
    |     Updates in Prefect workspace                                                          |
    |                                                                                           |
    |         - Create Azure Container Instance credentials block aci-push-pool-credentials     |
    |                                                                                           |
    _____________________________________________________________________________________________
    Proceed with infrastructure provisioning? [y/n]:     
    Creating resource group
    Creating app registration
    Generating secret for app registration
    Creating ACI credentials block
    ACI credentials block 'aci-push-pool-credentials' created in Prefect Cloud
    Assigning Contributor role to service account
    Creating Azure Container Registry
    Creating identity
    Provisioning infrastructure... ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 100% 0:00:00
    Infrastructure successfully provisioned for 'my-aci-work-pool' work pool!
    Created work pool 'my-aci-work-pool'!
    Checking for active workers...
    Active workers found. Skipping worker start instructions.
    ```

    <Tip>
    **Default Docker build namespace**
        After infrastructure provisioning completes, you are logged into your new Azure Container Registry and 
        the default Docker build namespace is set to the URL of the registry.
    </Tip>

        While the default namespace is set, any images you build without specifying a registry or username/organization 
        are pushed to the registry.

        To use this capability, write your deploy scripts like this:

        ```python example_deploy_script.py
        from prefect import flow
        from prefect.docker import DockerImage                                


        @flow(log_prints=True)                                                         
        def my_flow(name: str = "world"):
            print(f"Hello {name}! I'm a flow running on an Azure Container Instance!") 


        if __name__ == "__main__":
            my_flow.deploy(                                                            
                name="my-deployment",
                work_pool_name="my-work-pool",                                    
                image=DockerImage(                                                 
                    name="my-image:latest",                                       
                    platform="linux/amd64",                                            
                )                                                                 
            )       
        ```

        This builds an image with the tag `<acr-registry-url>/my-image:latest` and pushes it to the registry.
  </Tab>
  <Tab title="Google Cloud Run">

```bash
prefect work-pool create --type cloud-run:push --provision-infra my-cloud-run-pool 
```

The `--provision-infra` flag allows you to select a GCP project to use for your work pool and automatically 
configures it to execute flows through Cloud Run.
In your GCP project, this command activates the Cloud Run API, creates a service account, and creates a key for the 
service account, (if they don't already exist).
In your Prefect workspace, this command creates a 
[`GCPCredentials` block](/integrations/prefect-gcp/index#authenticate-using-a-gcp-credentials-block) to store the service account key.

Here's an abbreviated example output from running the command:
## Deploy and schedule your flow

A [deployment](/3.0/deploy/infrastructure-examples/docker/) is used to determine when, where, and how a flow should run.
Deployments elevate flows to remotely configurable entities that have their own API.

1. Create a deployment in code:

   ```bash create_deployment.py
   from prefect import flow

   # Source for the code to deploy (here, a GitHub repo)
   SOURCE_REPO="https://github.com/prefecthq/demos.git"

   if __name__ == "__main__":
       flow.from_source(
           source=SOURCE_REPO,
           entrypoint="my_gh_workflow.py:repo_info", # Specific flow to run
       ).deploy(
           name="my-first-deployment",
           work_pool_name="my-work-pool", # Work pool target
           cron="0 1 * * *", # Cron schedule (1am every day)
       )
   ```

   <Tip>
   You can store your flow code in nearly any location as long as Prefect can access it.
   See [Where to store your flow code](/3.0/deploy/infrastructure-concepts/store-flow-code) for more details.
   </Tip>

1. Run the script to create the deployment:

   ```bash
   python create_deployment.py
   ```

   Check the logs to ensure your deployment was created:

   ```bash
   Successfully created/updated all deployments!
   ______________________________________________________
   |                    Deployments                     |  
   ______________________________________________________
   |    Name                       |  Status  | Details |
   ______________________________________________________
   | repo-info/my-first-deployment | applied  |         |
   ______________________________________________________
   ```

1. Schedule a run for the deployment:

   ```bash
   prefect deployment run 'repo-info/my-first-deployment'
   ```

   Soon you should see the flow run graph and logs on the **Flow Run** page in the UI.
   Logs are also streamed to the terminal.

   ![Flow run graph and logs](/3.0/img/ui/qs-flow-run.png)

## Next steps

You've seen how to move from a Python script to a scheduled, observable, remotely orchestrated workflow with Prefect.
Now consider reading: 

* [Write flows](/3.0/develop/write-flows)
* [Write tasks](/3.0/develop/write-tasks)
* [Cloud and server](/3.0/manage)
* [Manage infrastructure with work pools](/3.0/deploy/infrastructure-concepts/work-pools) to learn about running workflows on Kubernetes, Docker, and serverless infrastructure.

<Tip>
Need help? [Book a meeting](https://calendly.com/prefect-experts/prefect-product-advocates?utm_campaign=prefect_docs_cloud&utm_content=prefect_docs&utm_medium=docs&utm_source=docs) with a Prefect Product Advocate to get your questions answered.
</Tip>
